version: "3.8"

services:
  spark-master:
    image: bitnami/spark:3.5.0
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=0.0.0.0  # Changed from spark-master
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_DAEMON_MEMORY=1g
      - SPARK_CONF_DIR=/opt/bitnami/spark/conf
      - SPARK_MASTER_OPTS="-Dspark.deploy.recoveryMode=NONE -Dspark.ui.host=0.0.0.0"
    ports:
      - "18081:8080"   # Spark Master Web UI
      - "7077:7077"    # Spark Cluster Communication
    volumes:
      - ./spark-apps:/opt/bitnami/spark/jobs
      - ./spark-data:/opt/bitnami/spark/data
      - spark-logs:/opt/bitnami/spark/logs
      - ./spark-config:/opt/bitnami/spark/conf
    networks:
      - snowplow-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://0.0.0.0:8080"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  spark-worker-1:
    image: bitnami/spark:3.5.0
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_WORKER_MEMORY=2g
      - SPARK_EXECUTOR_MEMORY=1800m  # Leave some buffer
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_OPTS="-Dspark.ui.host=0.0.0.0"
    ports:
      - "18082:8081"  # Web UI for Worker 1
    volumes:
      - ./spark-apps:/opt/bitnami/spark/jobs
      - ./spark-data:/opt/bitnami/spark/data
      - spark-logs:/opt/bitnami/spark/logs
#      - ./spark-config:/opt/bitnami/spark/conf
    depends_on:
      spark-master:
        condition: service_healthy
    networks:
      - snowplow-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://0.0.0.0:8081"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 45s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '2.0'

  spark-worker-2:
    image: bitnami/spark:3.5.0
    container_name: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8082
      - SPARK_WORKER_MEMORY=2g
      - SPARK_EXECUTOR_MEMORY=1800m
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_OPTS="-Dspark.ui.host=0.0.0.0"
    ports:
      - "18083:8082"  # Web UI for Worker 2
    volumes:
      - ./spark-apps:/opt/bitnami/spark/jobs
      - ./spark-data:/opt/bitnami/spark/data
      - spark-logs:/opt/bitnami/spark/logs
      - ./spark-config:/opt/bitnami/spark/conf
    depends_on:
      spark-master:
        condition: service_healthy
    networks:
      - snowplow-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://0.0.0.0:8082"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 45s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '2.0'

  # Removed history server - not supported in Bitnami image
  # Alternative: Use standalone history server or different image

volumes:
  spark-logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./spark-logs

networks:
  snowplow-network:
    external: true
